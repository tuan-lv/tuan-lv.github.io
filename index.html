
<html><head><meta http-equiv="Content-Type" content="text/html; charset=GBK">
<script async src="./analytics.js"></script><script type="text/javascript" src="./hidebib.js"></script>
<title>Tuan Le-Viet's Homepage</title>
<link rel="shortcut icon" href="https://tenticker.com/wp-content/uploads/2019/06/3c6d55fbb2fb43166132523b2ea4462309f7d345.jpg">
<style type="text/css">
body {
	margin-top: 30px;
	margin-bottom: 30px;
	margin-left: 100px;
	margin-right: 100px;
}
p {
	margin-top: 0px;
	margin-bottom: 0px;
}

.caption {
	font-size: 34px;
	font-weight: normal;
	color: #000;
	font-family: Constantia, "Lucida Bright", "DejaVu Serif", Georgia, serif;
}
.caption-1 {
	font-size: 16px;
	font-family: Tahoma, Geneva, sans-serif;
}
.caption-2 {
	font-size: 16px;
	font-family: Tahoma, Geneva, sans-serif;
	font-weight: bold;
	color: #990000;
}
.caption-3 {
	font-size: 16px;
	font-family: Tahoma, Geneva, sans-serif;
	font-weight: bold;
	color: #F00;
}
.caption-4 {
	font-size: 16px;
	font-family: Tahoma, Geneva, sans-serif;
	color: #990000;
}
.content {
	font-size: 16px;
	font-family: Tahoma, Geneva, sans-serif;
	text-align: justify;
}
.content a {
	font-size: 16px;
	font-family: Tahoma, Geneva, sans-serif;
	color: #000;
}
.content strong a {
	font-size: 16px;
	font-family: Tahoma, Geneva, sans-serif;
	color: #990000;
}
heading {
  font-family: 'Lato', Verdana, Helvetica, sans-serif;*/
  font-size: 15px;
  font-weight: 700
}
.title-small {
	font-size: 20px;
	font-family: Georgia, "Times New Roman", Times, serif;
	font-weight: bold;
	color: #F90;
}
.title-large {
	font-size: 28px;
	font-family: Georgia, "Times New Roman", Times, serif;
	font-weight: bold;
	color: #000;
}
.margin {
	font-size: 10px;
	line-height: 10px;
}
.margin-small {
	font-size: 5px;
	line-height: 5px;
}
.margin-large {
	font-size: 16px;
	line-height: 16px;
}
a:link {
	text-decoration: none;
}
a:visited {
	text-decoration: none;
}
content a:link {
	text-decoration: none;
}
content a:visited {
	text-decoration: none;
}
a:hover {
	text-decoration: underline;
}
a:active {
	text-decoration: underline;
	color: #06F;
	font-family: Tahoma, Geneva, sans-serif;
}
strong a:active {
	text-decoration: underline;
	color: #06F;
}
</style>
<script async="" src="./files/analytics.js.download"></script><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-53682931-1', 'auto');
  ga('send', 'pageview');

</script></head>



<body>

<table border="0" width="100%">
  <tbody>

    <tr>
    <td width="185"><img src="./files/portrait.jpg" border="1" height="250"></td>
    <td width="15"></td>
    <td></td>
    <td><table border="0" width="100%">
      <tbody><tr height="10">
        <td colspan="2"></td></tr>


         <tr height="20">
        <td>
           <p class="caption">Tuan Le-Viet</p>
           <p class="content">XXX</p>
           <p class="content">XXX</p>           
           <p class="content">HoChiMinh city, Vietnam</p>
        </td>
      </tr>

      <tr height="40">
        <td><table border="0" width="100%">
          <tbody><tr height="20">
            <td width="55">
              <p class="content"><strong>Email: </strong></p></td>
            <td>
              <p class="content"> tingchunw at nvidia dot com</p></td>
          </tr>          
        </tbody></table></td>
      </tr>

      <tr height="20">
        <td>
          <p class="margin">&nbsp;</p>
          <p class="content">
          <strong><a href="https://github.com/tcwang0509/">GitHub</a></strong> | 
          <strong><a href="https://scholar.google.com/citations?user=ajXAb54AAAAJ&hl=en">Google Scholar</a></strong> </p>
        </td>
      </tr>
      <tr height="20">
        <td colspan="2"></td></tr>
    </tbody></table></td>
  </tr>
</tbody></table>
<p class="margin">&nbsp;</p>

<table border="0">
  <tbody>
    <tr>
      <td width="1200"> <p align="justify" class="content">I'm a senior research scientist at NVIDIA, working on computer vision, machine learning and computer graphics. <br>
        I received my PhD from University of California, Berkeley in 2017, advised by Professor <strong><a href="https://cseweb.ucsd.edu/~ravir/" target="_blank" rel="nofollow" class="caption-2">Ravi Ramamoorthi</a></strong> and <strong><a href="http://www.eecs.berkeley.edu/~efros/" target="_blank" rel="nofollow" class="caption-2">Alexei A. Efros</a></strong>. <br>
        My recent research focus is on using generative adversarial models to synthesize realistic images and videos, with applications to rendering, visual manipulations and beyond.<br>
        <!--<em><b>I'm looking for interns to work on GAN related problems. If you're interested, please send me your resume and a brief introduction about yourself.</strong></b></p>-->
        <br>
    </td></tr>
  </tbody>
</table>

<br>

<p id="sect-news" class="title-large">News</p>
<ul>
  <li><p class="content">Our <a href="https://nvlabs.github.io/face-vid2vid"><strong>face-vid2vid paper</strong></a> is accepted by CVPR 2021 as an oral presentation!</li>
  <li><p class="content">Check out our new paper on <a href="https://nvlabs.github.io/wc-vid2vid/"><strong>world-consistent video synthesis</strong></a>!</li>
  <li><p class="content">I am co-organizing the <strong>Mixed Precision Tutorial</strong> at ECCV 2020. More details and slides can be found on the tutorial website. </li> 
  <li><p class="content">Two papers accepted by NeurIPS 2019! </li>
  <li><p class="content">I co-organized the <a href="https://nvlabs.github.io/iccv2019-mixed-precision-tutorial/"><strong>Mixed Precision  Tutorial</strong></a> at ICCV 2019. </li> 
  <li><p class="content">I served as an area chair in WACV 2020. </li>
  <li><p class="content">GauGAN won <strong>Best in Show Award</strong> and <strong>Audience Choice Award</strong> for RealTimeLive at SIGGRAPH 2019. Check out our <a href="https://www.nvidia.com/en-us/research/ai-playground/" target="_blank" rel="nofollow" class="caption-2">online demo</a>. </li>  
<!--   <li><p class="content">Our SPADE paper is accepted by CVPR 2019! See our <a href="https://www.youtube.com/watch?v=p5U4NgVGAwg" target="_blank" rel="nofollow" class="caption-2">GauGAN demo</a>. </li>
  <li><p class="content">Our vid2vid paper is accepted by NeurIPS 2018! See our <a href="https://www.youtube.com/watch?v=ayPqjPekn7g" target="_blank" rel="nofollow" class="caption-2">interactive demo</a>.</li>
  <li><p class="content">Received NTECH 2018 best paper award from NVIDIA.</li>
  <li><p class="content">Received NVIDIA Pioneer Research Award from NVIDIA.</li> -->
  <!--<li><p class="content">Won 1st place in <a href="http://bdd-data.berkeley.edu/wad-2018.html" target="_blank" rel="nofollow" class="caption-2">WAD Challenge</a>, Domain Adaptation for Semantic Segmentation Competition, CVPR 2018</li>
  <li><p class="content">Presented our <a href="https://youtu.be/sIkUzmgUaxc?t=1200" target="_blank" rel="nofollow" class="caption-2">pix2pixHD</a> work at CVPR 2018.</li>
  <li><p class="content">Check out our <a href="https://twitter.com/NVIDIAAIDev/status/1009873840246280192" target="_blank" rel="nofollow" class="caption-2">face demo</a> at CVPR 2018!</li> -->
<br>
</ul>

<p id="sect-publications" class="title-large">Publications</p>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="10">
  <tr> <td width="20%" valign="top"><a href="https://nvlabs.github.io/face-vid2vid/web_gifs/teaser.gif" class="hoverZoomLink"><img src="https://nvlabs.github.io/face-vid2vid/web_gifs/teaser_novelview.gif" alt="facevid2vid" width="100%" border="1"></a>
        <td width="80%" valign="top">
        <p>
        <heading>One-Shot Free-View Neural Talking-Head Synthesis for Video Conferencing</heading></a><br>
        <p class="margin">&nbsp;</p>        
        <p class="content"><strong>Ting-Chun Wang</strong>, <a href="https://arunmallya.github.io/">Arun Mallya</a>, <a href="http://mingyuliu.net/">Ming-Yu Liu</a></p>
        <p class="margin-small">&nbsp;</p>
        <p class="content"><em>IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2021
          <font color="red">(oral presentation)</font>
        <p class="margin">&nbsp;</p>
        
        <div class="paper" id="facevid2vid">    
        <p class="content">            
        <strong><a href="https://nvlabs.github.io/face-vid2vid">project</a></strong> |
        <strong><a href="https://nvlabs.github.io/face-vid2vid/main.pdf">paper</a></strong> |
        <strong><a href="https://www.youtube.com/watch?v=nLYg9Waw72U">YouTube</a></strong> |
        <strong><a shape="rect" href="javascript:togglebib('facevid2vid')" class="togglebib">bibtex</a></strong> </p>
        <pre xml:space="preserve" style="display: none;">
@inproceedings{wang2021facevid2vid,
   author    = {Ting-Chun Wang and Arun Mallya and Ming-Yu Liu},
   title     = {One-Shot Free-View Neural Talking-Head Synthesis for Video Conferencing},
   booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
   year      = {2021},
}
      </pre> </div> </td> </tr>

  
      </pre> </div> </td> </tr> 
            
      
      <tr>
      <td width="20%" valign="top"><a href="papers/PAMI15/specular_highres.png" class="hoverZoomLink"><img src="papers/PAMI15/specular.png" alt="glossy_pami" width="100%"  height="150" border="1"></a>
      <td width="80%" valign="top">
      <p><heading>Depth estimation and specular removal for glossy surfaces using <br>
          point and line consistency with light-field cameras</heading><br>
      <p class="margin">&nbsp;</p>
      <p class="content"><a href="http://www.cs.berkeley.edu/~mtao/">Michael Tao</a>, Jong-Chyi Su, <strong>Ting-Chun Wang</strong>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>, <a href="http://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a></p>
      <p class="margin-small">&nbsp;</p>
      <p class="content"><em>Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>)</em></p>
      <p class="margin">&nbsp;</p>
              
      <div class="paper" id="glossy_pami">
      <p class="content">
      <strong><a href="papers/PAMI15/LF_glossy_TPAMI.pdf">paper</a></strong> |      
      <strong><a shape="rect" href="javascript:togglebib('glossy_pami')" class="togglebib">bibtex</a> </p></strong>      
      <pre xml:space="preserve" style="display: none;">
@article{tao2015depth,
title={Depth Estimation and Specular Removal 
for Glossy Surfaces Using Point and 
Line Consistency with Light-Field Cameras},
author={Tao, Michael and Su, Jong-Chyi 
and Wang, Ting-Chun and Malik, Jitendra 
and Ramamoorthi, },
journal={IEEE Transactions on Pattern 
Analysis \& Machine Intelligence},
number={1},
pages={1--1},
year={2015},
publisher={IEEE}
}
      </pre></div></td></tr>
      
      
      <tr>
      <td width="20%" valign="top"><a href="papers/ECCV14/l4cv_highres.png" class="hoverZoomLink"><img src="papers/ECCV14/l4cv.jpg" alt="glossy" width="100%" height="150" border="1"></a>
      <td width="80%" valign="top">
      <p><heading>Depth estimation for glossy surfaces with light-field cameras</heading><br>
      <p class="margin">&nbsp;</p>
      <p class="content"><a href="http://www.cs.berkeley.edu/~mtao/">Michael Tao</a>, <strong>Ting-Chun Wang</strong>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>, <a href="http://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a></p>
      <p class="margin-small">&nbsp;</p>
      <p class="content"><em>ECCV workshop on Light Fields for Computer Vision (<strong>L4CV</strong>)</em>, 2014</p>
      <p class="margin">&nbsp;</p>
              
      <div class="paper" id="glossy">
      <p class="content">
      <strong><a href="papers/ECCV14/LF_glossy_ECCV14_s.pdf">paper</a></strong> |      
      <strong><a shape="rect" href="javascript:togglebib('glossy')" class="togglebib">bibtex</a> </p> </strong>      
      <pre xml:space="preserve" style="display: none;">
@inproceedings{tao2014depth,
title={Depth estimation for glossy 
surfaces with light-field cameras},
author={Tao, Michael W and Wang, Ting-Chun 
and Malik, Jitendra and Ramamoorthi, Ravi},
booktitle={Computer Vision-ECCV 2014 Workshops},
pages={533--547},
year={2014},
organization={Springer}
}
      </pre> </div> </td> </tr>    
      </table>
  </div>
  </div>
    </div>
    <div id="footer">
      
</div>

<script xml:space="preserve" language="JavaScript">
hideallbibs();
</script>


<div style="display:none">
<!-- GoStats JavaScript Based Code -->
<script type="text/javascript" src="./files/counter.js.download"></script><script language="javascript">var _go_js="1.0";</script><script language="javascript1.1">_go_js="1.1";</script><script language="javascript1.2">_go_js="1.2";</script><script language="javascript1.3">_go_js="1.3";</script><script language="javascript1.4">_go_js="1.4";</script><script language="javascript1.5">_go_js="1.5";</script><script language="javascript1.6">_go_js="1.6";</script><script language="javascript1.7">_go_js="1.7";</script><script language="javascript1.8">_go_js="1.8";</script><script language="javascript1.9">_go_js="1.9";</script><script language="javascript"></script>
<script type="text/javascript">_gos='c3.gostats.com';_goa=390583;
_got=4;_goi=1;_goz=0;_god='hits';_gol='web page statistics from GoStats';_GoStatsRun();</script><a target="_blank" href="http://gostats.com/" title="web page statistics from GoStats"><img id="_go_render_39058369" alt="web page statistics from GoStats" title="web page statistics from GoStats" border="0" style="border-width:0px" src="./files/count"></a>
<!-- <a target="_blank" title="web page statistics from GoStats"
href="http://gostats.com"> -->
</div>
<!--
<img alt="web page statistics from GoStats"
src="http://c3.gostats.com/bin/count/a_390583/t_4/i_1/z_0/show_hits/counter.png"
style="border-width:0" />
</a>
-->
<!-- End GoStats JavaScript Based Code -->

</body></html>
